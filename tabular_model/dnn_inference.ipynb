{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = '../data/balanced_data/normalized_metadata_inference.csv'\n",
    "model_path = 'saved_models/best_model.pth'\n",
    "output_csv = 'inference_results.csv'\n",
    "normalization_params_path = 'saved_models/normalization_params.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"patient_id\", \"lesion_id\", \"iddx_full\", \"iddx_1\", \"iddx_2\", \"iddx_3\", \"iddx_4\", \"iddx_5\",\n",
    "    \"mel_mitotic_index\", \"mel_thick_mm\", \"tbp_lv_dnn_lesion_confidence\", \"attribution\", \"copyright_license\",\n",
    "    \"image_type\", \"anatom_site_general\", \"tbp_tile_type\", \"tbp_lv_location\"\n",
    "]\n",
    "\n",
    "# Load the inference CSV\n",
    "data = pd.read_csv(input_csv)\n",
    "\n",
    "# Step 1: Drop unnecessary columns\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 2: Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Step 3: Convert 'sex' to binary\n",
    "data['sex'] = data['sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Step 4: One-hot encode 'tbp_lv_location_simple'\n",
    "data = pd.get_dummies(data, columns=['tbp_lv_location_simple'], prefix='', prefix_sep='', dtype=int)\n",
    "\n",
    "# Step 5: Rename one-hot encoded columns to match training format\n",
    "data.rename(\n",
    "    columns={col: col.lower().replace(' ', '_') for col in data.columns if col.startswith(('Torso', 'Left', 'Right', 'Head', 'Unknown'))},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Step 6: Convert True/False to 1/0\n",
    "data = data.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
    "\n",
    "# Separate ISIC IDs\n",
    "isic_ids = data['isic_id']\n",
    "\n",
    "# Step 7: Normalize non-binary features\n",
    "with open(normalization_params_path, 'r') as f:\n",
    "    normalization_params = json.load(f)\n",
    "\n",
    "binary_columns = ['sex'] + [col for col in data.columns if col not in normalization_params and col != 'isic_id']\n",
    "features = data.drop(columns=['isic_id']).copy()\n",
    "\n",
    "for col, params in normalization_params.items():\n",
    "    col_min = params['min']\n",
    "    col_max = params['max']\n",
    "    features[col] = (features[col] - col_min) / (col_max - col_min)\n",
    "\n",
    "# Convert to tensor\n",
    "features_tensor = torch.tensor(features.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = features_tensor.shape[1]\n",
    "model = FeedforwardNN(input_dim=input_dim, hidden_dim=128, output_dim=2)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device)['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(features_tensor.to(device))\n",
    "    probabilities = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  \n",
    "\n",
    "\n",
    "results = pd.DataFrame({'isic_id': isic_ids, 'target': probabilities})\n",
    "results.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Inference results saved to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SUTD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
